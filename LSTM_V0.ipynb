{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheBlock98/Thesis/blob/main/LSTM_V0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2nRY2NFe4dL"
      },
      "source": [
        "We want to build a LSTM model to predict future price  \n",
        "(HLC3) of BTC using dataSetIMRCleaned.csv like dataSet.\n",
        "First of all  we want to predict HLC3 to one step, in the second phase we want build multiOutput model to\n",
        "predict HLC3 to:  1 steps in this phase. We implement using pyTorch.\n",
        "\n",
        "We want use Boruta to do PCA and select important features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iLiUTSIYqyJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-5OxZiCZIimG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gjo-4uV5InTb"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"data\": {\n",
        "        \"window_size\": 200,\n",
        "        \"train_split_size\": 0.70,\n",
        "        \"test_split_size\": 0.20,\n",
        "        \"valid_split_size\": 0.10,\n",
        "\n",
        "    },\n",
        "\n",
        "    \"model\": {\n",
        "        \"input_size\": 62,  # since we are only using 62 feature, close price\n",
        "        \"num_lstm_layers\": 1,\n",
        "        \"lstm_size\": 64,\n",
        "        \"dropout\": 0.8,\n",
        "        \"num_class\": 1,\n",
        "        \"model_path\": \"/content/drive/MyDrive/Colab Notebooks\",\n",
        "        \"model_name\": \"LSTMV0.txt\",\n",
        "        \"save_model\": True,\n",
        "    },\n",
        "    \"training\": {\n",
        "        #\"device\": \"cpu\",  # \"cuda\" or \"cpu\"\n",
        "        \"batch_size\": 64,\n",
        "        \"num_epochs\": 100,\n",
        "        \"learning_rate\": 0.01, # 1e-3\n",
        "        \"loss_function\": nn.MSELoss(),\n",
        "        \"optimizer\": torch.optim.Adam,\n",
        "        \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        \"scheduler_patience\": 3,\n",
        "        \"scheduler_factor\": 0.5,\n",
        "        \"scheduler_min_lr\": 1e-6,\n",
        "        \"early_stopping\": True,\n",
        "        \"early_stopping_patience\": 20,\n",
        "\n",
        "\n",
        "\n",
        "      },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhU2GmMcXE30",
        "outputId": "65cc04eb-4bb4-498d-fa08-9eddf1c9c9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2PvPkX7GIsfF"
      },
      "outputs": [],
      "source": [
        "dataSet = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataSetIMRNormalized.csv\")\n",
        "hlc3 = dataSet['hlc3']\n",
        "dataSet.drop(labels=['hlc3'], axis=1, inplace=True)\n",
        "dataSet.insert(0, 'hlc3', hlc3)\n",
        "\n",
        "# Dataloading (sliding windows)\n",
        "config[\"model\"][\"input_size\"] = dataSet.shape[1] # with 1 have number of features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U2z3CCWAIzjr"
      },
      "outputs": [],
      "source": [
        "def sliding_windows(df, windowSize):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(len(df) - windowSize):\n",
        "    # Convert DataFrame slice to values and append to x\n",
        "    _x = df.iloc[i:(i + windowSize)].values\n",
        "    # Append the hlc3 value at position i + windowSize as the target\n",
        "    _y = df.iloc[i + windowSize][\"hlc3\"]\n",
        "    x.append(_x)\n",
        "    y.append(_y)\n",
        "\n",
        "  return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV0kIZDOI7S3",
        "outputId": "63fb2753-8113-4975-c61f-8d4394dea667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50144, 200, 62])\n",
            "torch.Size([5014, 200, 62])\n"
          ]
        }
      ],
      "source": [
        "x, y = sliding_windows(dataSet, config[\"data\"][\"window_size\"])\n",
        "train_size = int(len(y) * config[\"data\"][\"train_split_size\"])\n",
        "val_size = int(len(y) * config[\"data\"][\"valid_split_size\"])\n",
        "test_size = int(len(y) * config[\"data\"][\"test_split_size\"])\n",
        "\n",
        "# transform from np.array  x and y to tensors\n",
        "dataX = Variable(torch.Tensor(np.array(x)))\n",
        "dataY = Variable(torch.Tensor(np.array(y)))\n",
        "\n",
        "print(dataX.size())\n",
        "# split seqences into train and test\n",
        "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
        "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
        "valX = Variable(torch.Tensor(np.array(x[train_size:train_size + val_size])))\n",
        "valY = Variable(torch.Tensor(np.array(y[train_size:train_size + val_size])))\n",
        "print(valX.size())\n",
        "testX = Variable(torch.Tensor(np.array(x[train_size + val_size:])))\n",
        "testY = Variable(torch.Tensor(np.array(y[train_size + val_size:])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ILuz15L4JDNf"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, num_lstm_layers, lstm_size, dropout, num_class):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.input_size = 62\n",
        "    self.num_lstm_layers = num_lstm_layers\n",
        "    self.lstm_size = lstm_size\n",
        "    self.dropout = dropout\n",
        "    self.num_class = num_class\n",
        "\n",
        "    # Fully connected layer as input layer\n",
        "    self.fc_input = nn.Linear(62, lstm_size)\n",
        "\n",
        "\n",
        "    # Define the LSTM layers\n",
        "    self.lstm = nn.LSTM(input_size=config[\"model\"][\"lstm_size\"],\n",
        "                        hidden_size=config[\"model\"][\"lstm_size\"],\n",
        "                        num_layers=config[\"model\"][\"num_lstm_layers\"],\n",
        "                        dropout=dropout,\n",
        "                        batch_first=True)\n",
        "    # Define the Dropout layer\n",
        "    # self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    # Define the output fully connected layer\n",
        "    # Define the output fully connected layer\n",
        "    self.fc_output = nn.Linear(lstm_size, config[\"model\"][\"num_class\"])\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Pass data through the input fully connected layer\n",
        "    x = self.fc_input(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Initialize hidden and cell states with zeros\n",
        "    h_0 = Variable(torch.zeros(self.num_lstm_layers, x.size(0), self.lstm_size))\n",
        "    c_0 = Variable(torch.zeros(self.num_lstm_layers, x.size(0), self.lstm_size))\n",
        "\n",
        "      # Pass through LSTM layers\n",
        "    out = x\n",
        "    for i in range(self.num_lstm_layers):\n",
        "      out, (h_0, c_0) = self.lstm(out, (h_0.detach(), c_0.detach()))\n",
        "      out = F.relu(out)\n",
        "      if self.num_lstm_layers > 1:\n",
        "        out = self.dropout_layer(out)\n",
        "\n",
        "    out = out[:, -1, :]\n",
        "    # Output layer\n",
        "    output = self.fc_output(out)  # Sele\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrpjRPhUJG_k",
        "outputId": "96307ae7-6cae-492c-90ec-6c6b71da34c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "model = LSTM(input_size=config[\"model\"][\"input_size\"],\n",
        "             num_lstm_layers=config[\"model\"][\"num_lstm_layers\"],\n",
        "             lstm_size=config[\"model\"][\"lstm_size\"],\n",
        "             dropout=config[\"model\"][\"dropout\"],\n",
        "             num_class=1)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"])\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=config[\"training\"][\"learning_rate\"], weight_decay=weight_decay)\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=config[\"training\"][\"learning_rate\"], weight_decay=weight_decay)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=config[\"training\"][\"learning_rate\"])\n",
        "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "scheduler = config[\"training\"][\"scheduler\"](optimizer, patience=config[\"training\"][\"scheduler_patience\"],\n",
        "                                            factor=config[\"training\"][\"scheduler_factor\"],\n",
        "                                            min_lr=config[\"training\"][\"scheduler_min_lr\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jZwgqaovJQ4V"
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "class EarlyStoppingException(Exception):\n",
        "  pass\n",
        "\n",
        "def training(model, optimizer, criterion, scheduler, trainX, trainY, valX, valY, epoch, best_val_loss,patience_counter):\n",
        "  print(f\"Epoch {epoch+1} \\n ---------- \")\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(trainX)\n",
        "  outputs = outputs.squeeze(-1)  # Squeeze the output to match the target\n",
        "  loss = criterion(outputs, trainY)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Evaluate the model and compute validation loss\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      val_outputs = model(valX)\n",
        "      val_outputs = val_outputs.squeeze(-1)  # Squeeze the output to match the target\n",
        "      val_loss = criterion(val_outputs, valY)\n",
        "\n",
        "  # Reduced learning rate when a metric has stopped improving\n",
        "  scheduler.step(val_loss)\n",
        "  # Check for early stopping\n",
        "  if config[\"training\"][\"early_stopping\"]:\n",
        "      if val_loss < best_val_loss:\n",
        "          best_val_loss = val_loss.item()  # Capture the best validation loss\n",
        "          patience_counter = 0  # Reset counter if validation loss improves\n",
        "      else:\n",
        "          patience_counter += 1\n",
        "          # Stop training if val_loss has not improved after patience limit\n",
        "          if patience_counter >= config[\"training\"][\"early_stopping_patience\"]:\n",
        "              print(f'Early stopping: val_loss has not improved ' +\n",
        "                    f'for {config[\"training\"][\"early_stopping_patience\"]} consecutive epochs.')\n",
        "              raise EarlyStoppingException()\n",
        "\n",
        "\n",
        "  # Output training/validation statistics\n",
        "  print(f'Epoch[{epoch+1}/{config[\"training\"][\"num_epochs\"]}] | ' +\n",
        "        f'Loss train: {loss.item():.6f}, ' +\n",
        "        f'Loss val: {val_loss.item():.6f} | ' +\n",
        "        f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}'+\n",
        "       f\"best validation loss: {best_val_loss:.6f}\" )\n",
        "  return loss, val_loss, best_val_loss, patience_counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EbneLH58JUfT"
      },
      "outputs": [],
      "source": [
        "def testing(model,testX,testY,criterion):\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(testX)\n",
        "        test_outputs = test_outputs.squeeze(-1)\n",
        "\n",
        "        test_loss = criterion(test_outputs, testY)\n",
        "        print(f'Test loss: {test_loss.item():.6f}')\n",
        "    # compute performance KPY MSE, RMSE, MAE, accuracy, r2\n",
        "    y_pred = test_outputs.detach().numpy()\n",
        "    y_true = testY.detach().numpy()\n",
        "    kpy_mse = mean_squared_error(y_true, y_pred)\n",
        "    kpy_rmse = np.sqrt(kpy_mse)\n",
        "    kpy_mae = mean_absolute_error(y_true, y_pred)\n",
        "    kpy_r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f'KPY MSE: {kpy_mse:.6f}, RMSE: {kpy_rmse:.6f}, MAE: {kpy_mae:.6f}, R2: {kpy_r2:.6f}')\n",
        "\n",
        "\n",
        "    return test_outputs,kpy_mse, kpy_rmse, kpy_mae, kpy_r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGVHJ13nJVlw",
        "outputId": "34538078-5d95-4454-db6e-c0b4a593c5eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 1 \n",
            " ---------- \n",
            "Epoch[1/100] | Loss train: 0.014588, Loss val: 0.026053 | LR: 0.010000best validation loss: 0.003619\n",
            "Test loss: 0.014385\n",
            "KPY MSE: 0.014385, RMSE: 0.119936, MAE: 0.114832, R2: -1.514834\n",
            "Best validation loss: 0.003619\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 2 \n",
            " ---------- \n",
            "Epoch[2/100] | Loss train: 0.022456, Loss val: 0.019779 | LR: 0.010000best validation loss: 0.003619\n",
            "Test loss: 0.013895\n",
            "KPY MSE: 0.013895, RMSE: 0.117876, MAE: 0.115275, R2: -1.429164\n",
            "Best validation loss: 0.003619\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 3 \n",
            " ---------- \n",
            "Epoch[3/100] | Loss train: 0.015218, Loss val: 0.002251 | LR: 0.010000best validation loss: 0.002251\n",
            "Test loss: 0.002382\n",
            "KPY MSE: 0.002382, RMSE: 0.048804, MAE: 0.048289, R2: 0.583589\n",
            "Best validation loss: 0.002251\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 4 \n",
            " ---------- \n",
            "Epoch[4/100] | Loss train: 0.003357, Loss val: 0.005163 | LR: 0.010000best validation loss: 0.002251\n",
            "Test loss: 0.002138\n",
            "KPY MSE: 0.002138, RMSE: 0.046241, MAE: 0.039613, R2: 0.626173\n",
            "Best validation loss: 0.002251\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 5 \n",
            " ---------- \n",
            "Epoch[5/100] | Loss train: 0.002060, Loss val: 0.021480 | LR: 0.010000best validation loss: 0.002251\n",
            "Test loss: 0.012599\n",
            "KPY MSE: 0.012599, RMSE: 0.112245, MAE: 0.103894, R2: -1.202629\n",
            "Best validation loss: 0.002251\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 6 \n",
            " ---------- \n",
            "Epoch[6/100] | Loss train: 0.007202, Loss val: 0.024835 | LR: 0.010000best validation loss: 0.002251\n",
            "Test loss: 0.015122\n",
            "KPY MSE: 0.015122, RMSE: 0.122972, MAE: 0.113371, R2: -1.643769\n",
            "Best validation loss: 0.002251\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 7 \n",
            " ---------- \n",
            "Epoch[7/100] | Loss train: 0.008104, Loss val: 0.015591 | LR: 0.005000best validation loss: 0.002251\n",
            "Test loss: 0.008983\n",
            "KPY MSE: 0.008983, RMSE: 0.094777, MAE: 0.084136, R2: -0.570430\n",
            "Best validation loss: 0.002251\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 8 \n",
            " ---------- \n",
            "Early stopping: val_loss has not improved for 5 consecutive epochs.\n",
            "Early stopping triggered, proceeding to the next epoch...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(config[\"training\"][\"num_epochs\"]):\n",
        "    try:\n",
        "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "        loss, val_loss, best_val_loss, patience_counter = training(model, optimizer, criterion, scheduler, trainX, trainY, valX, valY, epoch, best_val_loss, patience_counter)\n",
        "        test_outputs, kpy_mse, kpy_rmse, kpy_mae, kpy_r2 = testing(model, testX, testY, criterion)\n",
        "    except EarlyStoppingException:\n",
        "        print(\"Early stopping triggered, proceeding to the next epoch...\")\n",
        "        continue\n",
        "    print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsSnW4F9JY43",
        "outputId": "fc8f7c37-95d4-4f1a-bfb2-644f0ab1aff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModelLSTMV0 saved to /content/drive/MyDrive/ColabNotebooks\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/LSTM_V0.pth\")\n",
        "print(f'ModelLSTMV0 saved to /content/drive/MyDrive/ColabNotebooks')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur6I6O7iJeUf"
      },
      "outputs": [],
      "source": [
        "data_predict = test_outputs.data.numpy()\n",
        "dataY_plot = testY.data.numpy()\n",
        "# denormalize data\n",
        "data_predict = scaler.inverse_transform(data_predict)\n",
        "dataY_plot = scaler.inverse_transform(dataY_plot)\n",
        "# invert scaling for plotting\n",
        "dataY_plot = dataY_plot[:, 0]\n",
        "data_predict = data_predict[:, 0]\n",
        "# invert scaling for plotting\n",
        "dataY_plot = dataY_plot[-len(data_predict):]\n",
        "data_predict = data_predict[-len(data_predict):]\n",
        "# Plot predictions vs. actual\n",
        "plt.plot(dataY_plot, label='Data')\n",
        "plt.plot(data_predict, label='Predictions')\n",
        "plt.legend()\n",
        "plt.axvline(x=train_size, c='r', linestyle='--')\n",
        "plt.suptitle('Time-Series Prediction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(range(len(all_targets)), all_targets, color='blue', label='Targets', alpha=0.5, marker='o')\n",
        "plt.scatter(range(len(all_predictions)), all_predictions, color='red', label='Predictions', alpha=0.5, marker='x')\n",
        "\n",
        "plt.title('Predictions vs Targets')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
